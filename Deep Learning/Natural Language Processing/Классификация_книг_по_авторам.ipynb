{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhV6Y-HOTyXW",
        "outputId": "3587a89f-41ab-4c0c-ec90-e79e79f9d29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odPOcaNEWCm4"
      },
      "outputs": [],
      "source": [
        "!rm -R /content/texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQVy2YdLYLxF",
        "outputId": "d8ea17e7-5661-4d65-caf6-f369dda59555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 17:23:23--  https://github.com/a18091986/MachineLearning/blob/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/a18091986/MachineLearning/raw/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip [following]\n",
            "--2022-05-04 17:23:23--  https://github.com/a18091986/MachineLearning/raw/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/a18091986/MachineLearning/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip [following]\n",
            "--2022-05-04 17:23:23--  https://raw.githubusercontent.com/a18091986/MachineLearning/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8127897 (7.8M) [application/zip]\n",
            "Saving to: ‘/content/text’\n",
            "\n",
            "/content/text       100%[===================>]   7.75M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-05-04 17:23:23 (88.1 MB/s) - ‘/content/text’ saved [8127897/8127897]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://github.com/a18091986/MachineLearning/blob/main/Datasets/%D0%A2%D0%B5%D0%BA%D1%81%D1%82%D1%8B%20%D0%BF%D0%B8%D1%81%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.zip?raw=true' -O /content/text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uex00IkuX4VA"
      },
      "outputs": [],
      "source": [
        "!unzip -q '/content/text' -d /content/texts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG_NE1dYZWN6"
      },
      "outputs": [],
      "source": [
        "def readText(fileName):\n",
        "  with open(fileName, 'r') as f:\n",
        "    text = f.read().replace('\\n', ' ')\n",
        "    return text\n",
        "\n",
        "className = ['Генри', 'Стругацкие', 'Булгаков', 'Клиффорд', 'Макс', 'Брэдберри']\n",
        "nClasses = len(className)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCArSQe-bGof",
        "outputId": "c0f29ca1-7423-40d7-fd4b-5ff5718bdadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(О. Генри) Обучающая_50 вместе.txt добавлен в обучающую выборку\n",
            "(О. Генри) Тестовая_20 вместе.txt добавлен в тестовую выборку\n",
            "****************************************************************************************************\n",
            "(Стругацкие) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Стругацкие) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "****************************************************************************************************\n",
            "(Булгаков) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "(Булгаков) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "****************************************************************************************************\n",
            "(Клиффорд_Саймак) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Клиффорд_Саймак) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "****************************************************************************************************\n",
            "(Макс Фрай) Обучающая_5 вместе.txt добавлен в обучающую выборку\n",
            "(Макс Фрай) Тестовая_2 вместе.txt добавлен в тестовую выборку\n",
            "****************************************************************************************************\n",
            "(Рэй Брэдберри) Обучающая_22 вместе.txt добавлен в обучающую выборку\n",
            "(Рэй Брэдберри) Тестовая_8 вместе.txt добавлен в тестовую выборку\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "trainText = []\n",
        "testText = []\n",
        "\n",
        "for i in className:\n",
        "  for j in os.listdir('/content/texts/Тексты писателей/'):\n",
        "    if i in j:\n",
        "      if 'Обучающая' in j:\n",
        "        trainText.append(readText('/content/texts/Тексты писателей/'+j))\n",
        "        print(f'{j} добавлен в обучающую выборку')\n",
        "      if 'Тестовая' in j:\n",
        "        testText.append(readText('/content/texts/Тексты писателей/'+j))\n",
        "        print(f'{j} добавлен в тестовую выборку')\n",
        "  print(\"*\"*100)\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vnxG2Vbcld_q",
        "outputId": "b7222336-4fd7-4aa7-a221-411953a06fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'время работы: 3.16'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cur_time = time.time()\n",
        "maxWordsCount = 15000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters = '')\n",
        "# tokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff', lower=True, split=' ', oov_token='unknown', char_level=False)\n",
        "tokenizer.fit_on_texts(trainText)\n",
        "items = list(tokenizer.word_index.items())\n",
        "f'время работы: {round(time.time() - cur_time, 2)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49RGrUFHm_nD"
      },
      "outputs": [],
      "source": [
        "trainWordIndexes = tokenizer.texts_to_sequences(trainText)\n",
        "testWordIndexes = tokenizer.texts_to_sequences(testText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZa7I_f_CW7r"
      },
      "outputs": [],
      "source": [
        "# Формирование обучающей выборки по листу индексов слов\n",
        "# (разделение на короткие векторы)\n",
        "def getSetFromIndexes(wordIndexes, xLen, step): # функция принимает последовательность индексов, размер окна, шаг окна\n",
        "  xSample = [] # Объявляем переменную для векторов\n",
        "  wordsLen = len(wordIndexes) # Считаем количество слов\n",
        "  index = 0 # Задаем начальный индекс \n",
        "\n",
        "  while (index + xLen <= wordsLen):# Идём по всей длине вектора индексов\n",
        "    xSample.append(wordIndexes[index:index+xLen]) # \"Откусываем\" векторы длины xLen\n",
        "    index += step # Смещаеммся вперёд на step\n",
        "    \n",
        "  return xSample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1aQHjbRGsN-"
      },
      "outputs": [],
      "source": [
        "# Формирование обучающей и проверочной выборки\n",
        "# Из двух листов индексов от двух классов\n",
        "def createSetsMultiClasses(wordIndexes, xLen, step): # Функция принимает последовательность индексов, размер окна, шаг окна\n",
        "\n",
        "  # Для каждого из 6 классов\n",
        "  # Создаём обучающую/проверочную выборку из индексов\n",
        "  nClasses = len(wordIndexes) # Задаем количество классов выборки\n",
        "  classesXSamples = []        # Здесь будет список размером \"кол-во классов*кол-во окон в тексте*длину окна (например, 6 по 1341*1000)\"\n",
        "  for wI in wordIndexes:      # Для каждого текста выборки из последовательности индексов\n",
        "    classesXSamples.append(getSetFromIndexes(wI, xLen, step)) # Добавляем в список очередной текст индексов, разбитый на \"кол-во окон*длину окна\" \n",
        "\n",
        "  # Формируем один общий xSamples\n",
        "  xSamples = [] # Здесь будет список размером \"суммарное кол-во окон во всех текстах*длину окна (например, 15779*1000)\"\n",
        "  ySamples = [] # Здесь будет список размером \"суммарное кол-во окон во всех текстах*вектор длиной 6\"\n",
        "  \n",
        "  for t in range(nClasses): # В диапазоне кол-ва классов(6)\n",
        "    xT = classesXSamples[t] # Берем очередной текст вида \"кол-во окон в тексте*длину окна\"(например, 1341*1000)\n",
        "    for i in range(len(xT)): # И каждое его окно\n",
        "      xSamples.append(xT[i]) # Добавляем в общий список выборки\n",
        "      ySamples.append(utils.to_categorical(t, nClasses)) # Добавляем соответствующий вектор класса\n",
        "\n",
        "  xSamples = np.array(xSamples) # Переводим в массив numpy для подачи в нейронку\n",
        "  ySamples = np.array(ySamples) # Переводим в массив numpy для подачи в нейронку\n",
        "\n",
        "  \n",
        "  return (xSamples, ySamples) #Функция возвращает выборку и соответствующие векторы классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjS87A0uSc7"
      },
      "outputs": [],
      "source": [
        "xLen = 5000\n",
        "step = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c20SL1NIuos-"
      },
      "outputs": [],
      "source": [
        "xTrain, yTrain = createSetsMultiClasses(trainWordIndexes, xLen, step)\n",
        "xTest, yTest = createSetsMultiClasses(testWordIndexes, xLen, step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRSgXkdju1LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6ccddb-66ee-4894-cd69-e84bd7fa1a14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13291, 5000), (13291, 6), (4579, 5000), (4579, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "xTrain.shape, yTrain.shape, xTest.shape, yTest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSnpV9ksvDbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730a4be0-77b1-47e5-8d97-4effcef70c1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13291, 15000), (4579, 15000))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "xTrainBoW = tokenizer.sequences_to_matrix(xTrain.tolist())\n",
        "xTestBoW = tokenizer.sequences_to_matrix(xTest.tolist())\n",
        "xTrainBoW.shape, xTestBoW.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stHRW8-4mf7G"
      },
      "outputs": [],
      "source": [
        "# Представляем тестовую выборку в удобных для распознавания размерах\n",
        "def createTestMultiClasses(wordIndexes, xLen, step): #функция принимает последовательность индексов, размер окна, шаг окна\n",
        "\n",
        "  #Для каждого из 6 классов\n",
        "  #Создаём тестовую выборку из индексов\n",
        "  nClasses = len(wordIndexes) #Задаем количество классов\n",
        "  xTest6Classes01 = []               #Здесь будет список из всех классов, каждый размером \"кол-во окон в тексте * 20000 (при maxWordsCount=20000)\"\n",
        "  xTest6Classes = []                 #Здесь будет список массивов, каждый размером \"кол-во окон в тексте * длину окна\"(6 по 420*1000)\n",
        "  for wI in wordIndexes:                       #Для каждого тестового текста из последовательности индексов\n",
        "    sample = (getSetFromIndexes(wI, xLen, step)) #Тестовая выборка размером \"кол-во окон*длину окна\"(например, 420*1000)\n",
        "    xTest6Classes.append(sample)              # Добавляем в список\n",
        "    xTest6Classes01.append(tokenizer.sequences_to_matrix(sample)) #Трансформируется в Bag of Words в виде \"кол-во окон в тексте * 20000\"\n",
        "  xTest6Classes01 = np.array(xTest6Classes01)                     #И добавляется к нашему списку, \n",
        "  xTest6Classes = np.array(xTest6Classes)                     #И добавляется к нашему списку, \n",
        "  \n",
        "  return xTest6Classes01, xTest6Classes  #функция вернёт тестовые данные: TestBag 6 классов на n*20000 и xTestEm 6 по n*1000\n",
        "\n",
        "# Распознаём тестовую выборку и выводим результаты\n",
        "def recognizeMultiClass(model, xTest, modelName):\n",
        "  print(\"НЕЙРОНКА: \", modelName)\n",
        "  print()\n",
        "  \n",
        "  totalSumRec = 0 # Сумма всех правильных ответов\n",
        "  \n",
        "  #Проходим по всем классам\n",
        "  for i in range(nClasses):\n",
        "    #Получаем результаты распознавания класса по блокам слов длины xLen\n",
        "    currPred = model.predict(xTest[i])\n",
        "    #Определяем номер распознанного класса для каждохо блока слов длины xLen\n",
        "    currOut = np.argmax(currPred, axis=1)\n",
        "\n",
        "    evVal = []\n",
        "    for j in range(nClasses):\n",
        "      evVal.append(len(currOut[currOut==j])/len(xTest[i]))\n",
        "\n",
        "    totalSumRec += len(currOut[currOut==i])\n",
        "    recognizedClass = np.argmax(evVal) #Определяем, какой класс в итоге за какой был распознан\n",
        "    \n",
        "    #Выводим результаты распознавания по текущему классу\n",
        "    isRecognized = \"Это НЕПРАВИЛЬНЫЙ ответ!\"\n",
        "    if (recognizedClass == i):\n",
        "      isRecognized = \"Это ПРАВИЛЬНЫЙ ответ!\"\n",
        "    str1 = 'Класс: ' + className[i] + \" \" * (11 - len(className[i])) + str(int(100*evVal[i])) + \"% сеть отнесла к классу \" + className[recognizedClass]\n",
        "    print(str1, \" \" * (55-len(str1)), isRecognized, sep='')\n",
        "  \n",
        "  #Выводим средний процент распознавания по всем классам вместе\n",
        "  print()\n",
        "  sumCount = 0\n",
        "  for i in range(nClasses):\n",
        "    sumCount += len(xTest[i])\n",
        "  print(\"Средний процент распознавания \", int(100*totalSumRec/sumCount), \"%\", sep='')\n",
        "\n",
        "  print()\n",
        "  \n",
        "  return totalSumRec/sumCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2pauYH44EVa"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "lr = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7HDDPwWyb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7a5539-f48e-45a3-a601-568ac3df58e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "xTestBoW_, xTestEmbedding = createTestMultiClasses(testWordIndexes, xLen, step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82iKN-3N3XnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06354ca8-565a-4a65-df87-ca8f9c67472a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "208/208 [==============================] - 7s 22ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.2035 - val_accuracy: 0.9616\n",
            "Epoch 2/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 8.4244e-05 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9631\n",
            "Epoch 3/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 4.3250e-05 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9642\n",
            "Epoch 4/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 2.5276e-05 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9640\n",
            "Epoch 5/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.6865e-05 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9651\n",
            "Epoch 6/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 1.1824e-05 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9655\n",
            "Epoch 7/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 8.4951e-06 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9657\n",
            "Epoch 8/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 6.6331e-06 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9661\n",
            "Epoch 9/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 5.3162e-06 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9672\n",
            "Epoch 10/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 4.4434e-06 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9661\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2000, input_dim = maxWordsCount, activation = 'relu'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(6, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = lr), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "result = model.fit(xTrainBoW, yTrain, epochs = epochs, batch_size = batch_size, validation_data = (xTestBoW, yTest))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = lr/2), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "result = model.fit(xTrainBoW, yTrain, epochs = epochs, batch_size = batch_size, validation_data = (xTestBoW, yTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFIuJ_cJy1hG",
        "outputId": "857d0284-dc43-44bf-f456-dae9d8896475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "208/208 [==============================] - 5s 22ms/step - loss: 1.4967e-06 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9764\n",
            "Epoch 2/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 3.1521e-07 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9801\n",
            "Epoch 3/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 1.4941e-07 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9803\n",
            "Epoch 4/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 9.0625e-08 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9825\n",
            "Epoch 5/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 6.2147e-08 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9814\n",
            "Epoch 6/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 4.4030e-08 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9823\n",
            "Epoch 7/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 3.4576e-08 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9834\n",
            "Epoch 8/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 2.8522e-08 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9841\n",
            "Epoch 9/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 2.1481e-08 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 2.0046e-08 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = lr/4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "result = model.fit(xTrainBoW, yTrain, epochs = epochs, batch_size = batch_size, validation_data = (xTestBoW, yTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D424meKrDAQF",
        "outputId": "c119a476-143c-4250-af0e-7ea56a153a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "208/208 [==============================] - 5s 23ms/step - loss: 1.7239e-08 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9838\n",
            "Epoch 2/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.8046e-08 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9838\n",
            "Epoch 3/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 1.6216e-08 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9838\n",
            "Epoch 4/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.4117e-08 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
            "Epoch 5/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.5678e-08 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9841\n",
            "Epoch 6/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.2449e-08 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9843\n",
            "Epoch 7/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.2279e-08 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9841\n",
            "Epoch 8/10\n",
            "208/208 [==============================] - 4s 21ms/step - loss: 1.1337e-08 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9841\n",
            "Epoch 9/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 1.1068e-08 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9841\n",
            "Epoch 10/10\n",
            "208/208 [==============================] - 4s 20ms/step - loss: 1.1732e-08 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVJGzDyq34WF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989ab273-89b3-4c8d-dd9f-a555cfcc7493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "НЕЙРОНКА:  Bow+Softmax\n",
            "\n",
            "Класс: Генри      100% сеть отнесла к классу Генри     Это ПРАВИЛЬНЫЙ ответ!\n",
            "Класс: Стругацкие 96% сеть отнесла к классу Стругацкие Это ПРАВИЛЬНЫЙ ответ!\n",
            "Класс: Булгаков   99% сеть отнесла к классу Булгаков   Это ПРАВИЛЬНЫЙ ответ!\n",
            "Класс: Клиффорд   100% сеть отнесла к классу Клиффорд  Это ПРАВИЛЬНЫЙ ответ!\n",
            "Класс: Макс       97% сеть отнесла к классу Макс       Это ПРАВИЛЬНЫЙ ответ!\n",
            "Класс: Брэдберри  100% сеть отнесла к классу Брэдберри Это ПРАВИЛЬНЫЙ ответ!\n",
            "\n",
            "Средний процент распознавания 98%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred = recognizeMultiClass(model_2, xTestBoW_, 'Bow+Softmax')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Классификация_книг_по_авторам.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}